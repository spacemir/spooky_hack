{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Read-the-data\" data-toc-modified-id=\"Read-the-data-0.0.0.1\"><span class=\"toc-item-num\">0.0.0.1&nbsp;&nbsp;</span>Read the data</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Predict\" data-toc-modified-id=\"Predict-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Predict</a></span></li><li><span><a href=\"#Build-a-second-pipe-line\" data-toc-modified-id=\"Build-a-second-pipe-line-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Build a second pipe-line</a></span></li><li><span><a href=\"#Try-with-a-random-search-grid\" data-toc-modified-id=\"Try-with-a-random-search-grid-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Try with a random search grid</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import  pprint\n",
    "import  subprocess \n",
    "import sys \n",
    "sys.path.append('../')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the labels as numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(train.author.values)\n",
    "\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.text.values, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -(1.0 / rows) * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "\n",
    "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
    "ctv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_ctv =  ctv.transform(xtrain) \n",
    "xvalid_ctv = ctv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.485 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on Counts\n",
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain_ctv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=False,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_tfv =  tfv.transform(xtrain) \n",
    "xvalid_tfv = tfv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17621, 15102)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.579 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on Counts\n",
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV] nb__alpha=0.001 .................................................\n",
      "[CV] nb__alpha=0.001 .................................................\n",
      "[CV] nb__alpha=0.01 ..................................................\n",
      "[CV] nb__alpha=0.01 ..................................................\n",
      "[CV] ....... nb__alpha=0.001, score=-0.6197727138113207, total=   0.0s\n",
      "[CV] ....... nb__alpha=0.001, score=-0.6405281207644529, total=   0.1s\n",
      "[CV] nb__alpha=0.1 ...................................................\n",
      "[CV] ........ nb__alpha=0.01, score=-0.5107077210899634, total=   0.0s\n",
      "[CV] nb__alpha=0.1 ...................................................\n",
      "[CV] ........ nb__alpha=0.01, score=-0.5227750429194576, total=   0.0s\n",
      "[CV] nb__alpha=1 .....................................................\n",
      "[CV] nb__alpha=1 .....................................................\n",
      "[CV] ........ nb__alpha=0.1, score=-0.48977643250586556, total=   0.1s\n",
      "[CV] ........ nb__alpha=0.1, score=-0.49542834857941936, total=   0.0s\n",
      "[CV] ........... nb__alpha=1, score=-0.6636804830313953, total=   0.1s\n",
      "[CV] nb__alpha=10 ....................................................\n",
      "[CV] nb__alpha=100 ...................................................\n",
      "[CV] ........... nb__alpha=1, score=-0.6670828777424888, total=   0.0s\n",
      "[CV] ......... nb__alpha=100, score=-1.0672620913597066, total=   0.0s\n",
      "[CV] .......... nb__alpha=10, score=-0.9498100532224479, total=   0.0s\n",
      "[CV] nb__alpha=10 ....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1216s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:    0.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    0.3s remaining:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] nb__alpha=100 ...................................................\n",
      "[CV] .......... nb__alpha=10, score=-0.9507075585052208, total=   0.0s\n",
      "[CV] .......... nb__alpha=100, score=-1.067347892749627, total=   0.0s\n",
      "Best score: -0.493\n",
      "Best parameters set:\n",
      "\tnb__alpha: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "mll_scorer = metrics.make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('nb', nb_model)])\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
    "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(xtrain_tfv, ytrain)  # we can use the full data here but im only using xtrain. \n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.model_selection._search.BaseSearchCV.predict_proba>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8392, 15102)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = test.text.values\n",
    "xtest_tfv =  tfv.transform(xtest) \n",
    "xtest_tfv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16204179, 0.05630826, 0.78164995],\n",
       "       [0.8852836 , 0.08006336, 0.03465305],\n",
       "       [0.3409618 , 0.64702109, 0.01201712],\n",
       "       ...,\n",
       "       [0.82935608, 0.08435844, 0.08628548],\n",
       "       [0.18011817, 0.02492834, 0.79495349],\n",
       "       [0.10903673, 0.88732942, 0.00363384]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(xtest_tfv)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.predict(xtrai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"id\", \"EAP\", \"HPL\", \"MWS\"])\n",
    "df[\"id\"] = test['id']\n",
    "df[\"EAP\"] = model.predict_proba(xtest_tfv)[:, 0]\n",
    "df[\"HPL\"] = model.predict_proba(xtest_tfv)[:, 1]\n",
    "df[\"MWS\"] = model.predict_proba(xtest_tfv)[:, 2]\n",
    "df.to_csv('./prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>0.162042</td>\n",
       "      <td>0.056308</td>\n",
       "      <td>0.781650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>0.885284</td>\n",
       "      <td>0.080063</td>\n",
       "      <td>0.034653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>0.340962</td>\n",
       "      <td>0.647021</td>\n",
       "      <td>0.012017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>0.493556</td>\n",
       "      <td>0.501627</td>\n",
       "      <td>0.004817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>0.834570</td>\n",
       "      <td>0.110247</td>\n",
       "      <td>0.055183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       EAP       HPL       MWS\n",
       "0  id02310  0.162042  0.056308  0.781650\n",
       "1  id24541  0.885284  0.080063  0.034653\n",
       "2  id00134  0.340962  0.647021  0.012017\n",
       "3  id27757  0.493556  0.501627  0.004817\n",
       "4  id04081  0.834570  0.110247  0.055183"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a second pipe-line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=1,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n",
    "            use_idf=1, smooth_idf=1, sublinear_tf=False, stop_words = 'english')\n",
    "\n",
    "mb = MultinomialNB()\n",
    "\n",
    "clf = pipeline.Pipeline([('tfv', tfv), ('mb', mb)])\n",
    "\n",
    "param_grid = {'tfv__ngram_range' : [(1, 1), (1, 2), (2, 4)],\n",
    "              'mb__alpha': [0.1, 0.5,  1.0]}\n",
    "\n",
    "\n",
    "\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
    "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(xtrain, ytrain)  # we can use the full data here but im only using xtrain. \n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV] mb__alpha=0.1, tfv__ngram_range=(1, 1) ..........................\n",
      "[CV] mb__alpha=0.1, tfv__ngram_range=(1, 1) ..........................\n",
      "[CV] mb__alpha=0.1, tfv__ngram_range=(1, 2) ..........................\n",
      "[CV] mb__alpha=0.1, tfv__ngram_range=(1, 2) ..........................\n",
      "[CV]  mb__alpha=0.1, tfv__ngram_range=(1, 1), score=-0.5039381043430531, total=   1.2s\n",
      "[CV]  mb__alpha=0.1, tfv__ngram_range=(1, 1), score=-0.49443189410997285, total=   1.3s\n",
      "[CV] mb__alpha=0.1, tfv__ngram_range=(2, 4) ..........................\n",
      "[CV] mb__alpha=0.1, tfv__ngram_range=(2, 4) ..........................\n",
      "[CV]  mb__alpha=0.1, tfv__ngram_range=(1, 2), score=-0.49960986214232195, total=   2.2s\n",
      "[CV] mb__alpha=1.0, tfv__ngram_range=(1, 1) ..........................\n",
      "[CV]  mb__alpha=0.1, tfv__ngram_range=(1, 2), score=-0.4914413902153785, total=   2.5s\n",
      "[CV] mb__alpha=1.0, tfv__ngram_range=(1, 1) ..........................\n",
      "[CV]  mb__alpha=1.0, tfv__ngram_range=(1, 1), score=-0.6652286895442716, total=   1.6s\n",
      "[CV] mb__alpha=1.0, tfv__ngram_range=(1, 2) ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    6.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  mb__alpha=1.0, tfv__ngram_range=(1, 1), score=-0.6698978911845287, total=   1.6s\n",
      "[CV] mb__alpha=1.0, tfv__ngram_range=(1, 2) ..........................\n",
      "[CV]  mb__alpha=0.1, tfv__ngram_range=(2, 4), score=-0.8952759027046554, total=   6.6s\n",
      "[CV] mb__alpha=1.0, tfv__ngram_range=(2, 4) ..........................\n",
      "[CV]  mb__alpha=0.1, tfv__ngram_range=(2, 4), score=-0.8958904100442969, total=   6.7s\n",
      "[CV] mb__alpha=1.0, tfv__ngram_range=(2, 4) ..........................\n",
      "[CV]  mb__alpha=1.0, tfv__ngram_range=(1, 2), score=-0.7212198315655546, total=   3.8s\n",
      "[CV] mb__alpha=10, tfv__ngram_range=(1, 1) ...........................\n",
      "[CV]  mb__alpha=1.0, tfv__ngram_range=(1, 2), score=-0.7256043724888017, total=   3.6s\n",
      "[CV] mb__alpha=10, tfv__ngram_range=(1, 1) ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   11.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  mb__alpha=10, tfv__ngram_range=(1, 1), score=-0.9462171882438013, total=   1.7s\n",
      "[CV] mb__alpha=10, tfv__ngram_range=(1, 2) ...........................\n",
      "[CV]  mb__alpha=10, tfv__ngram_range=(1, 1), score=-0.9474584088889313, total=   1.7s\n",
      "[CV] mb__alpha=10, tfv__ngram_range=(1, 2) ...........................\n",
      "[CV]  mb__alpha=1.0, tfv__ngram_range=(2, 4), score=-1.0255528425476406, total=   7.4s\n",
      "[CV] mb__alpha=10, tfv__ngram_range=(2, 4) ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  13 out of  18 | elapsed:   19.8s remaining:    7.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  mb__alpha=1.0, tfv__ngram_range=(2, 4), score=-1.0250757021574313, total=   7.4s\n",
      "[CV] mb__alpha=10, tfv__ngram_range=(2, 4) ...........................\n",
      "[CV]  mb__alpha=10, tfv__ngram_range=(1, 2), score=-0.9878162701596147, total=   4.8s\n",
      "[CV]  mb__alpha=10, tfv__ngram_range=(1, 2), score=-0.9886457723455158, total=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  18 | elapsed:   20.3s remaining:    4.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  mb__alpha=10, tfv__ngram_range=(2, 4), score=-1.0790228807512339, total=   3.9s\n",
      "[CV]  mb__alpha=10, tfv__ngram_range=(2, 4), score=-1.0790759629192066, total=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   24.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.496\n",
      "Best parameters set:\n",
      "\tmb__alpha: 0.1\n",
      "\ttfv__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with a random search grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform = sp.stats.uniform(0.01, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] mb__alpha=0.03000015827808987, tfv__ngram_range=(2, 4) ..........\n",
      "[CV] mb__alpha=0.03000015827808987, tfv__ngram_range=(2, 4) ..........\n",
      "[CV] mb__alpha=0.049367244385197545, tfv__ngram_range=(2, 4) .........\n",
      "[CV] mb__alpha=0.049367244385197545, tfv__ngram_range=(2, 4) .........\n",
      "[CV]  mb__alpha=0.03000015827808987, tfv__ngram_range=(2, 4), score=-0.883524073696141, total=   3.9s\n",
      "[CV] mb__alpha=0.011329767222323702, tfv__ngram_range=(1, 1) .........\n",
      "[CV]  mb__alpha=0.03000015827808987, tfv__ngram_range=(2, 4), score=-0.8805139842775999, total=   4.0s\n",
      "[CV]  mb__alpha=0.049367244385197545, tfv__ngram_range=(2, 4), score=-0.8792038660007394, total=   4.0s\n",
      "[CV]  mb__alpha=0.049367244385197545, tfv__ngram_range=(2, 4), score=-0.8781179408115126, total=   4.0s\n",
      "[CV] mb__alpha=0.05314623116577253, tfv__ngram_range=(1, 1) ..........\n",
      "[CV] mb__alpha=0.011329767222323702, tfv__ngram_range=(1, 1) .........\n",
      "[CV] mb__alpha=0.05314623116577253, tfv__ngram_range=(1, 1) ..........\n",
      "[CV]  mb__alpha=0.011329767222323702, tfv__ngram_range=(1, 1), score=-0.5075041584510929, total=   1.8s\n",
      "[CV] mb__alpha=0.04560163909446411, tfv__ngram_range=(1, 1) ..........\n",
      "[CV]  mb__alpha=0.011329767222323702, tfv__ngram_range=(1, 1), score=-0.525836877857276, total=   1.7s\n",
      "[CV] mb__alpha=0.04560163909446411, tfv__ngram_range=(1, 1) ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    8.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  mb__alpha=0.05314623116577253, tfv__ngram_range=(1, 1), score=-0.4849256202369818, total=   1.7s\n",
      "[CV]  mb__alpha=0.05314623116577253, tfv__ngram_range=(1, 1), score=-0.49655724232496307, total=   1.7s\n",
      "[CV] mb__alpha=0.03388584381222716, tfv__ngram_range=(2, 4) ..........\n",
      "[CV] mb__alpha=0.03388584381222716, tfv__ngram_range=(2, 4) ..........\n",
      "[CV]  mb__alpha=0.04560163909446411, tfv__ngram_range=(1, 1), score=-0.48454300214409984, total=   1.8s\n",
      "[CV] mb__alpha=0.03979681042368726, tfv__ngram_range=(1, 2) ..........\n",
      "[CV]  mb__alpha=0.04560163909446411, tfv__ngram_range=(1, 1), score=-0.49675318125849804, total=   1.8s\n",
      "[CV] mb__alpha=0.03979681042368726, tfv__ngram_range=(1, 2) ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   11.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  mb__alpha=0.03979681042368726, tfv__ngram_range=(1, 2), score=-0.46667318310819883, total=   4.6s\n",
      "[CV]  mb__alpha=0.03979681042368726, tfv__ngram_range=(1, 2), score=-0.4769108297148564, total=   4.6s\n",
      "[CV] mb__alpha=0.03804031560695873, tfv__ngram_range=(1, 2) ..........\n",
      "[CV] mb__alpha=0.03804031560695873, tfv__ngram_range=(1, 2) ..........\n",
      "[CV]  mb__alpha=0.03388584381222716, tfv__ngram_range=(2, 4), score=-0.8812651929645912, total=   7.3s\n",
      "[CV] mb__alpha=0.05388553728745226, tfv__ngram_range=(1, 1) ..........\n",
      "[CV]  mb__alpha=0.03388584381222716, tfv__ngram_range=(2, 4), score=-0.8787744167247004, total=   7.5s\n",
      "[CV] mb__alpha=0.05388553728745226, tfv__ngram_range=(1, 1) ..........\n",
      "[CV]  mb__alpha=0.05388553728745226, tfv__ngram_range=(1, 1), score=-0.4849944230543829, total=   1.9s\n",
      "[CV] mb__alpha=0.05064167389848534, tfv__ngram_range=(1, 1) ..........\n",
      "[CV]  mb__alpha=0.05388553728745226, tfv__ngram_range=(1, 1), score=-0.49657499015717393, total=   1.9s\n",
      "[CV] mb__alpha=0.05064167389848534, tfv__ngram_range=(1, 1) ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:   20.8s remaining:    5.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  mb__alpha=0.03804031560695873, tfv__ngram_range=(1, 2), score=-0.4663578975060131, total=   4.1s\n",
      "[CV]  mb__alpha=0.03804031560695873, tfv__ngram_range=(1, 2), score=-0.47672830606530714, total=   4.1s\n",
      "[CV]  mb__alpha=0.05064167389848534, tfv__ngram_range=(1, 1), score=-0.484730315457137, total=   1.7s\n",
      "[CV]  mb__alpha=0.05064167389848534, tfv__ngram_range=(1, 1), score=-0.496541848313532, total=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   22.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.472\n",
      "Best parameters set:\n",
      "\tmb__alpha: 0.03804031560695873\n",
      "\ttfv__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "tfv = TfidfVectorizer(min_df=1,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n",
    "            use_idf=1, smooth_idf=1, sublinear_tf=False, stop_words = 'english')\n",
    "\n",
    "mb = MultinomialNB()\n",
    "\n",
    "clf = pipeline.Pipeline([('tfv', tfv), ('mb', mb)])\n",
    "\n",
    "param_dis= {'tfv__ngram_range' : [(1, 1), (1, 2), (2, 4)],\n",
    "              'mb__alpha': sp.stats.uniform(0.01, 0.05)}\n",
    "\n",
    "\n",
    "\n",
    "model = RandomizedSearchCV(estimator=clf, param_distributions=param_dis, n_iter=10,  scoring=mll_scorer,\n",
    "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(xtrain, ytrain)  # we can use the full data here but im only using xtrain. \n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-c080f6458562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
